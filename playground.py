import random
import numpy as np
import torch 
from torch import nn
# valuationF = np.array([[0.78900805,0.96012449,0.99099806,0.58527462,0.63666145],\
#                 [0.98648185,0.55739215,0.19698906,0.68369219,0.27437320],\
#                 [0.86374709,0.85091796,0.43573782,0.13482168,0.40099636],\
#                 [0.58141219,0.22629741,0.66612841,0.97642836,0.79005999],\
#                 [0.30114841,0.11199923,0.01076650,0.66018063,0.51939904],\
#                 [0.83135732,0.50467929,0.34803428,0.23014417,0.93165713],\
#                 [0.90753162,0.45139716,0.12398481,0.87917376,0.95310834],\
#                 [0.15536485,0.47051726,0.36178991,0.84614371,0.27937186],\
#                 [0.46667823,0.16453699,0.61319562,0.41454692,0.11260570],\
#                 [0.89602795,0.06285511,0.93314658,0.97294757,0.86253819],\
#                 [0.35162777,0.27674798,0.92889346,0.25404701,0.06598934],\
#                 [0.20304112,0.12649533,0.10892991,0.84067924,0.33471859],\
#                 [0.41421655,0.78001907,0.19546347,0.03083713,0.24251268],\
#                 [0.83174977,0.05870072,0.54456963,0.35504824,0.57398383],\
#                 [0.04114803,0.28719724,0.76151723,0.68865910,0.15022888],\
#                 [0.39452686,0.16493265,0.86196355,0.13994046,0.35771739],\
#                 [0.90833496,0.83428713,0.75482767,0.29083134,0.06442374],\
#                 [0.33674271,0.28909863,0.67971812,0.01846276,0.81958546],\
#                 [0.49674642,0.72062413,0.07787972,0.24753036,0.55676578],\
#                 [0.73727425,0.13167262,0.73926587,0.41809112,0.55647347]],dtype=np.float32)

agent_num,items_num = 20,5
# # valuation_set = [0.5,1]
# # ##初始化效用函数
# delta = 0
# Z = random.uniform((1-delta)/2, (1+delta)/2) 
# valuationF = np.zeros([agent_num,2**items_num],dtype=np.float64)
# for i in range(agent_num):
#     for j in range(2**items_num):
#         valuationF[i][j] = random.uniform(Z-(1-delta)/2,Z+(1-delta)/2)
# print(valuationF)

valuationF = np.array([[0.64422989,0.64852048,0.17552876,0.65605942,0.10421101,0.29783172,\
0.83167023,0.72710239,0.69911883,0.36055524,0.56043238,0.89148156,\
0.21727940,0.47260884,0.22731410,0.22463595,0.40391854,0.35494413,\
0.20756420,0.84173282,0.38944754,0.45647121,0.68821572,0.93140279,\
0.26122290,0.46747176,0.32910317,0.29290460,0.08654559,0.08827478,\
0.51585238,0.97264196],\
[0.80309535,0.49028031,0.69780136,0.79785981,0.75387782,0.8926316,\
0.76850462,0.53990113,0.41836065,0.67510053,0.14575996,0.66458630,\
0.24481466,0.35462484,0.96121660,0.39384051,0.64067621,0.09666408,\
0.94873798,0.01388010,0.44605413,0.42117696,0.57141417,0.64484383,\
0.53451603,0.25356551,0.62265068,0.84292451,0.57018700,0.02439202,\
0.43018071,0.59612253],\
[0.95020002,0.39705049,0.85900194,0.39807091,0.26759475,0.83908172,\
0.31034367,0.16151416,0.35527940,0.63818748,0.38211807,0.798634730,\
0.40365327,0.38077952,0.31562434,0.19607639,0.78395734,0.238896280,\
0.32659374,0.12322886,0.38241418,0.55824825,0.64764721,0.480071660,\
0.86209574,0.08831655,0.19473933,0.33917950,0.85692090,0.786453800,\
0.07213218,0.5733242],\
[0.95700099,0.19005298,0.25548477,0.06129158,0.2632088,0.18032292,\
0.89725530,0.50865237,0.01393140,0.57847377,0.86268236,0.01093963,\
0.38106435,0.26968847,0.14934438,0.29644389,0.43763405,0.38224328,\
0.14074959,0.27093798,0.37134736,0.03609901,0.73859789,0.33612946,\
0.92783303,0.57455747,0.66734027,0.93035670,0.97320278,0.29490946,\
0.15474710,0.5190580],\
[0.52520181,0.07813884,0.57497040,0.43227768,0.45677109,0.99498374,\
0.40715809,0.97537299,0.29530847,0.49924051,0.01470550,0.50365777,\
0.75621346,0.04722800,0.46238060,0.59563181,0.48511725,0.06609747,\
0.16995651,0.40489377,0.30116699,0.07294013,0.34747451,0.54765727,\
0.93745153,0.66974032,0.47472481,0.39324156,0.69633807,0.98595554,\
0.91485861,0.89160528],\
[0.62177208,0.54881923,0.70866599,0.95143151,0.66318669,0.32201757,\
0.45483133,0.43519868,0.63757234,0.02024034,0.02740662,0.58935678,\
0.49435134,0.92227231,0.55507999,0.65087216,0.59376141,0.59519895,\
0.55178449,0.03098758,0.34438004,0.57763112,0.86571779,0.53583666,\
0.12080908,0.45057694,0.01604018,0.22882484,0.18583692,0.26768187,\
0.43690589,0.50866516],\
[0.46653183,0.98742373,0.03010871,0.09678726,0.73642681,0.66703086,\
0.48784624,0.05311396,0.24991802,0.19494223,0.32638866,0.02637774,\
0.08642933,0.20048334,0.05570643,0.17679652,0.96147787,0.93040001,\
0.63853316,0.51716628,0.55499522,0.76711262,0.07086650,0.94397897,\
0.68652225,0.16808826,0.87267182,0.95618860,0.40658804,0.97345832,\
0.52622336,0.36690726],\
[0.86298616,0.00866902,0.59690983,0.17562604,0.88099978,0.05945476,\
0.74394433,0.45814462,0.37566772,0.98942849,0.23572043,0.60645170,\
0.60023284,0.20384080,0.55603390,0.61283586,0.58815608,0.50733491,\
0.71172030,0.69819381,0.13263789,0.35092358,0.69530046,0.10844091,\
0.36948189,0.33113155,0.05580917,0.16593502,0.72227368,0.05428824,\
0.71161575,0.08411402],\
[0.55891451,0.28821012,0.85203603,0.36291163,0.00323454,0.16834022,\
0.05792681,0.51797552,0.93698093,0.99190255,0.96369718,0.97668788,\
0.26658981,0.75982371,0.87422782,0.67697387,0.61634702,0.19361791,\
0.67316541,0.18475347,0.84440457,0.23441807,0.66240909,0.61030031,\
0.76664041,0.34478964,0.46789545,0.87299021,0.18477159,0.82653319,\
0.92977915,0.66938746],\
[0.13481933,0.23601653,0.42695673,0.83983949,0.42312938,0.19469388,\
0.23072183,0.35556377,0.35369155,0.14163503,0.16777914,0.62601121,\
0.00178124,0.60961375,0.06989740,0.81061768,0.44354022,0.58720826,\
0.24623006,0.12047014,0.99395965,0.49559665,0.99981083,0.96148999,\
0.22317546,0.69749174,0.23425326,0.35624700,0.13552335,0.37687918,\
0.56244189,0.51145374],\
[0.99911611,0.33415786,0.28547333,0.48964527,0.66145998,0.64513447,\
0.89298686,0.99192021,0.44201511,0.58910071,0.15584149,0.12264672,\
0.89295709,0.79410169,0.17957178,0.58894949,0.25245489,0.36952121,\
0.22114028,0.98406460,0.59883119,0.57334642,0.84484373,0.23075879,\
0.36876674,0.77483869,0.89934276,0.90977389,0.74017237,0.68048858,\
0.41643921,0.90993722],\
[0.78440252,0.73477848,0.31390077,0.82942781,0.02341445,0.92420134,\
0.08595416,0.13214423,0.70943255,0.95126590,0.08074732,0.58576953,\
0.93221223,0.91937674,0.77699839,0.24820380,0.03939380,0.23339808,\
0.04841061,0.73146484,0.72617412,0.83431241,0.24859378,0.41827830,\
0.07496064,0.78066546,0.00317823,0.52585961,0.95223992,0.40011307,\
0.75584930,0.98755314],\
[0.21891688,0.33795348,0.93659714,0.64850212,0.08912108,0.5034216,\
0.43014676,0.14642547,0.15877199,0.33798738,0.64563114,0.34143050,\
0.10375229,0.02667278,0.08882378,0.37070085,0.28541722,0.66996734,\
0.97642549,0.09603222,0.92407370,0.32312977,0.95195496,0.13725952,\
0.52352817,0.31250153,0.46905561,0.39931880,0.44052161,0.62646881,\
0.12074081,0.07353049],\
[0.57793248,0.59281914,0.34006038,0.81571163,0.25179739,0.54187727,\
0.40469241,0.20889303,0.00892668,0.67073701,0.09385960,0.46757741,\
0.23309479,0.77196688,0.99838020,0.43683515,0.93949549,0.76907951,\
0.26407394,0.37833494,0.01714764,0.42162428,0.24504666,0.56159911,\
0.24957582,0.40732579,0.52308186,0.39544977,0.99734310,0.68141962,\
0.95163790,0.04097978],\
[0.49973531,0.82507569,0.57557687,0.08136136,0.55995646,0.23980375,\
0.96820187,0.64403914,0.42814394,0.97217048,0.88072624,0.53785743,\
0.82730625,0.80340468,0.71609454,0.83787784,0.75032117,0.34796834,\
0.49850091,0.51352607,0.75937341,0.42415875,0.02934962,0.49570550,\
0.99509118,0.49351730,0.23179814,0.10391609,0.31595417,0.24720251,\
0.21661971,0.99730109],\
[0.43867884,0.24456846,0.84491522,0.90331526,0.01396194,0.84710947,\
0.25731734,0.13962040,0.25314462,0.43873593,0.52571316,0.56831446,\
0.43817015,0.16852826,0.09439465,0.73681571,0.66945248,0.13752239,\
0.75643321,0.73640049,0.86819350,0.22746837,0.42042864,0.80847175,\
0.31735032,0.60407626,0.94552686,0.82094304,0.68975791,0.14778232,\
0.90558301,0.97962606],\
[0.71351427,0.50046642,0.05768543,0.64199325,0.90992810,0.09702464,\
0.35480515,0.23607391,0.14601829,0.52567861,0.08958811,0.48398748,\
0.96724350,0.79438880,0.47800841,0.87972653,0.69146534,0.47045379,\
0.79836209,0.67429231,0.51087017,0.67953372,0.56966048,0.37651413,\
0.76841503,0.75079354,0.67305894,0.82587292,0.56613539,0.82349006,\
0.43263237,0.8641809],\
[0.38416447,0.44284360,0.19050429,0.45390241,0.23926375,0.14726773,\
0.95059590,0.60000937,0.56674550,0.54416805,0.05520793,0.95509637,\
0.07556526,0.72260102,0.81954995,0.41454475,0.38624021,0.68400853,\
0.60763567,0.90447103,0.01567203,0.98846495,0.03913584,0.04542541,\
0.12483406,0.01002938,0.13142275,0.78409983,0.86309500,0.57686851,\
0.29956166,0.26838945],\
[0.47466704,0.74114246,0.92146759,0.01739490,0.66504218,0.49884803,\
0.85979968,0.38308709,0.39758828,0.80903350,0.48876636,0.70035937,\
0.03242988,0.05702881,0.63149595,0.95603914,0.32348444,0.20265002,\
0.13679741,0.57309656,0.39336172,0.03106096,0.50227004,0.63269594,\
0.07601464,0.52880957,0.85436170,0.48702902,0.78736735,0.33150275,\
0.27181190,0.87699836],\
[0.35089663,0.10885665,0.37273990,0.03632110,0.71186183,0.01092061,\
0.19606030,0.13127714,0.84108921,0.33915881,0.23574512,0.72680235,\
0.65146732,0.98229461,0.90837801,0.99396105,0.40748009,0.32393257,\
0.33902357,0.95514717,0.70782637,0.05856213,0.02387649,0.16577139,\
0.09361163,0.44724115,0.49629159,0.73410172,0.03632991,0.25768286,\
0.93141571,0.06329816]],dtype=np.float32)

print(valuationF)
#valuationF = np.array([[0.82056380,0.75085814,0.80649213,0.66718547,0.60177665],\
#                         [0.53871496,0.74116998,0.49023755,0.62529961,0.4677421,],\
#                         [0.62154513,0.81398764,0.77809160,0.75786980,0.80643186],\
#                         [0.46361577,0.52044746,0.64082748,0.58416801,0.58064334],\
#                         [0.48211456,0.64155361,0.44931744,0.49571730,0.54663379],\
#                         [0.46265119,0.90379159,0.43233035,0.71572148,0.80563687],\
#                         [0.74083186,0.85450743,0.66100919,0.46618217,0.69468876],\
#                         [0.49596751,0.89237095,0.53653965,0.43185060,0.57823526],\
#                         [0.61859413,0.49970378,0.59842140,0.81216326,0.57596745],\
#                         [0.55972638,0.76856466,0.68641035,0.78481651,0.76458924],\
#                         [0.81899059,0.78442305,0.56599245,0.78768933,0.74641114],\
#                         [0.80398142,0.45395139,0.80307528,0.53886493,0.90721872],\
#                         [0.84707981,0.91099478,0.75209413,0.91383390,0.53991594],\
#                         [0.82544360,0.47809490,0.47348607,0.69055768,0.80206644],\
#                         [0.48382233,0.53648629,0.53495853,0.82113082,0.88336502],\
#                         [0.78600917,0.52984319,0.69554863,0.78972415,0.68049813],\
#                         [0.54490653,0.64418488,0.85025338,0.84758725,0.68067916],\
#                         [0.87237872,0.77965879,0.86154242,0.48100582,0.47905533],\
#                         [0.65490038,0.85809629,0.64363378,0.69315903,0.56082043],\
#                         [0.81865368,0.43906551,0.87875157,0.71037880,0.86828593]],dtype=np.float32)
# print(valuationF)
# maxlie = np.amax(valuationF,axis=0)
# print(maxlie)
# print(sum(maxlie))

# def softmax(X):
#     X_exp = X.exp() 
#     partition = X_exp.sum(dim=0, keepdim=True) 
#     return X_exp / partition # 这⾥应⽤了⼴播机制

# probs = torch.tensor([0.2,0.5,0.7])
# probs_after = softmax(probs) 
# print(probs_after)
# value,inci = probs_after.sort(descending=True)
# print(value,inci)


# class Policy(nn.Module):
#     def __init__(self, in_dim, n_hidden_1, n_hidden_2, num_outputs):
#         super(Policy, self).__init__()
#         self.layer = nn.Sequential(
#             nn.Linear(in_dim, n_hidden_1),
#             nn.ReLU(True),
#             nn.Linear(n_hidden_1, n_hidden_2),
#             nn.ReLU(True),
#             nn.Linear(n_hidden_2, num_outputs)
#         )

# class Normal(nn.Module):
#     def __init__(self, num_outputs):
#         super().__init__()
#         self.stds = nn.Parameter(torch.zeros(num_outputs))
#         print("self.stds:",self.stds)
#     def forward(self, x):
#         dist = torch.distributions.Normal(loc=x, scale=self.stds.exp())
#         action = dist.sample()
#         return action

# if __name__ == '__main__':
#     policy = Policy(4,20,20,5)
#     normal = Normal(5)
#     observation = torch.Tensor(4)
#     print("obervation:",observation)
#     action = normal.forward(policy.layer(observation))
#     print("action: ",action)